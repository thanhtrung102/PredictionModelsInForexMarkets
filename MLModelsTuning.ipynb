{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def _dtw(output, target, window):\n",
    "    n, m = len(output), len(target)\n",
    "    w = np.max([window, abs(n-m)])\n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    dtw_matrix += float(\"Inf\")\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    for i in range(1, n+1):\n",
    "        a, b = np.max([1, i-w]), np.min([m, i+w])+1\n",
    "        dtw_matrix[i,a:b] = 0\n",
    "        \n",
    "        \n",
    "        for j in range(a, b):\n",
    "            cost = np.abs(output[i-1] - target[j-1])\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "            \n",
    "    return dtw_matrix[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"kernel\": ['rbf','linear','poly'],\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"gamma\":[0.0001,0.001,0.01],\n",
    "    \"degree\":[1,2,3]\n",
    "}\n",
    "svr = SVR()\n",
    "gssvr = GridSearchCV(svr, params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "#pipe2 = Pipeline([('poly2', PolynomialFeatures(2)), ('linReg', lr)])\n",
    "#pipe3 = Pipeline([('poly3', PolynomialFeatures(3)), ('linReg', lr)])\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "params = {\n",
    "    \"n_estimators\": [50,100,500]\n",
    "    \n",
    "}\n",
    "rfg = RandomForestRegressor()\n",
    "gsrfg = GridSearchCV(rfg, params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "params = {\n",
    "    \"max_iter\": [100,1000,2000],\n",
    "    \"tol\": [1e-6, 1e-8, 1e-10]\n",
    "}\n",
    "br = BayesianRidge()\n",
    "gsbr= GridSearchCV(br, params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "params = {\n",
    "    \"n_neighbors\": [50, 100, 300, 1000],\n",
    "    \"weights\": ['uniform','distance'],\n",
    "    \"algorithm\": ['ball_tree', 'kd_tree', 'brute']\n",
    "    \n",
    "}\n",
    "knn = KNeighborsRegressor()\n",
    "gsknn = GridSearchCV(knn, params, scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Bayesian Ridge Regression\": gsbr,\n",
    "    \"Support Vector Regression\": gssvr,\n",
    "    \"Random Forest Regression\": gsrfg,\n",
    "    \"KNN-Regression\": gsknn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURCAD\n",
      "Linear Regression\n",
      "0\n",
      "1.7766133934783948\n",
      "Bayesian Ridge Regression\n",
      "{'max_iter': 1000, 'tol': 1e-06}\n",
      "2109.3162862500303\n",
      "Support Vector Regression\n"
     ]
    }
   ],
   "source": [
    "from Scripts.utils import *  \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Scripts.FastDTW import *\n",
    "\n",
    "columns = ['Date','Open','High','Low','Close','Volume','Yield','PercentageVolume',\n",
    "           'SMA6','EMA6','WMA6','HMA6','SMA20','EMA20','WMA20','HMA20','SMA50','EMA50','WMA50','HMA50',\n",
    "           'SMA100','EMA100','WMA100','HMA100','MACD','CCI','Stochastic Oscillator','RSI','ROC','PPO',\n",
    "           'KST','BOLU','BOLD','BOLM']\n",
    "\n",
    "\n",
    "\n",
    "for pair in os.listdir('DataReady'):\n",
    "    if pair in ['EURUSD','EURGBP','EURCAD','EURAUD','EURJPY','EURCHF','USDJPY','USDCAD','AUDCAD','GBPUSD','AUDUSD']:\n",
    "        print(pair)\n",
    "        data = pd.read_csv('DataReady/{}/{}_H4.csv'.format(pair, pair), names = columns, header = 0)\n",
    "        #data = data[:-23000]\n",
    "        toRemove = ['Volume', 'Date','High','Low','Open','Close']\n",
    "        df = selectData(data,toRemove)\n",
    "        closingPrices = data['Close']\n",
    "        closingPrices = closingPrices.reset_index(drop=True)\n",
    "        normDf = normalizeData(df)\n",
    "        images = generateImages(normDf)\n",
    "        images = np.array(images)\n",
    "\n",
    "        train_X, _, train_Y, _ = train_test_split(images, closingPrices[28:], test_size = 0.2,shuffle = True, random_state = 42)\n",
    "        _, test_X, _, test_Y = train_test_split(images, closingPrices[28:], test_size = 0.2,shuffle = False)\n",
    "        train_X, test_X = train_X.reshape(train_X.shape[0],28*28).astype(np.float32), test_X.reshape(test_X.shape[0],28*28).astype(np.float32)\n",
    "        \n",
    "        for clf in classifiers.keys():\n",
    "            print(clf)\n",
    "            test_hat_Y = classifiers[clf].fit(train_X, train_Y).predict(test_X)\n",
    "            best_param = 0\n",
    "            try:\n",
    "                best_param = classifiers[clf].best_params_\n",
    "                print(best_param)\n",
    "            except:\n",
    "                print(0)\n",
    "                \n",
    "            mse = np.mean((test_hat_Y-test_Y)**2)\n",
    "            corr = np.corrcoef(test_hat_Y, test_Y)[0,1]\n",
    "            dti = _dtw(np.array(test_hat_Y), np.array(test_Y), 1)\n",
    "            fast_dti = fastdtw(test_hat_Y, test_Y, 1)[0]\n",
    "            print(fast_dti)\n",
    "            \n",
    "            with open(\"Results/ResultsML.txt\",\"a+\") as f:\n",
    "                f.write(\"{}_H4,{},{},{},{},{},{}\\n\".format(pair, clf, mse, corr, dti, fast_dti, best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models/MLModels.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     13\u001b[39m classifiers = {\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLinear Regression\u001b[39m\u001b[33m\"\u001b[39m: LinearRegression(),\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBayesian Ridge Regression\u001b[39m\u001b[33m\"\u001b[39m: BayesianRidge(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mKNN Regression\u001b[39m\u001b[33m\"\u001b[39m: KNeighborsRegressor()\n\u001b[32m     19\u001b[39m }\n\u001b[32m     21\u001b[39m columns = [\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mOpen\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mVolume\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mYield\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mPercentageVolume\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     22\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mSMA6\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mEMA6\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mWMA6\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mHMA6\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mSMA20\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mEMA20\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mWMA20\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mHMA20\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mSMA50\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mEMA50\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mWMA50\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mHMA50\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     23\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mSMA100\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mEMA100\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mWMA100\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mHMA100\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mMACD\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mCCI\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mStochastic Oscillator\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mRSI\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mROC\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mPPO\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     24\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mKST\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mBOLU\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mBOLD\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mBOLM\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModels/MLModels.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     27\u001b[39m     models = json.load(f)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m os.listdir(\u001b[33m'\u001b[39m\u001b[33mDataReady\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Models/MLModels.json'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Scripts.utils import *\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "classifiers = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Bayesian Ridge Regression\": BayesianRidge(),\n",
    "    \"Support Vector Regression\": SVR(),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(),\n",
    "    \"KNN Regression\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "columns = ['Date','Open','High','Low','Close','Volume','Yield','PercentageVolume',\n",
    "           'SMA6','EMA6','WMA6','HMA6','SMA20','EMA20','WMA20','HMA20','SMA50','EMA50','WMA50','HMA50',\n",
    "           'SMA100','EMA100','WMA100','HMA100','MACD','CCI','Stochastic Oscillator','RSI','ROC','PPO',\n",
    "           'KST','BOLU','BOLD','BOLM']\n",
    "\n",
    "with open(\"Models/MLModels.json\",\"r\") as f:\n",
    "    models = json.load(f)\n",
    "for pair in os.listdir('DataReady'):\n",
    "    if len(pair)==6 and pair not in ['EURGBP','USDJPY','AUDUSD','AUDCAD','EURUSD','USDCAD','EURCAD','GBPUSD','EURCHF']:\n",
    "        print(pair)\n",
    "        data = pd.read_csv('DataReady/{}/{}_D1.csv'.format(pair, pair), names = columns, header = 0)\n",
    "        toRemove = ['Volume', 'Date','High','Low','Open','Close']\n",
    "        df = selectData(data,toRemove)\n",
    "        closingPrices = data['Close']\n",
    "        closingPrices = closingPrices.reset_index(drop=True)\n",
    "        normDf = normalizeData(df)\n",
    "        images = generateImages(normDf)\n",
    "        images = np.array(images)\n",
    "\n",
    "        train_X, _, train_Y, _ = train_test_split(images, closingPrices[28:], test_size = 0.2,shuffle = True, random_state = 42)\n",
    "        train_X = train_X.reshape(train_X.shape[0],28*28).astype(np.float32)\n",
    "        \n",
    "        for clf in classifiers.keys():\n",
    "            print(clf)\n",
    "            model = classifiers[clf].set_params(**models[clf][pair])\n",
    "            model.fit(train_X, train_Y)\n",
    "            # save the model to disk\n",
    "            filename = 'Models/{}_{}.sav'.format(clf.replace(\" \",\"\"),pair)\n",
    "            pickle.dump(model, open(filename, 'wb'))\n",
    "            #loaded_model = pickle.load(open(filename, 'rb'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
